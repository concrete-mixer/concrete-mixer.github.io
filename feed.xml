<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Concrète Mixer - shredded field recording ambience</title>
    <atom:link href="https://concrete-mixer.github.io/feed.xml" rel="self" type="application/rss+xml"/>
    <link>https://concrete-mixer.github.io/</link>
    <description>Audio coding, ambient sound, musique concrète, internet radio.</description>
    <pubDate>Sat, 06 May 2017 21:54:54 +1200</pubDate>
    
      <item>
        <title>Concrète Mixer now available on TuneIn</title>
        <link>https://concrete-mixer.github.io/2017/05/tunein</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2017/05/tunein</guid>
        <description>&lt;p&gt;Concrète Mixer is now available in TuneIn, either &lt;a href=&quot;http://tunein.com/radio/Concr%C3%A8te-Mixer-s291379/&quot;&gt;from the website&lt;/a&gt; or via its various apps.&lt;/p&gt;

&lt;p&gt;Just to prove it, here’s a TuneIn embedded player for the station:&lt;/p&gt;

&lt;iframe src=&quot;http://tunein.com/embed/player/s291379/&quot; style=&quot;width:100%;height:100px;&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot;&gt;&lt;/iframe&gt;
</description>
        <pubDate>Sat, 06 May 2017 00:00:00 +1200</pubDate>
      </item>
    
      <item>
        <title>Real time track data added to home page</title>
        <link>https://concrete-mixer.github.io/2017/04/real-time-track-data</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2017/04/real-time-track-data</guid>
        <description>&lt;p&gt;You should notice that there’s a “Now playing” section in the “hero image” on the home page which lists tracks currently playing in the Concrète Mixer audio stream. I’ve achieved this by:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Adding extra &lt;a href=&quot;http://opensoundcontrol.org&quot;&gt;OSC&lt;/a&gt; request calls to &lt;code class=&quot;highlighter-rouge&quot;&gt;playSound.ck&lt;/code&gt; within Concrète Mixer, which broadcast the file name being played&lt;/li&gt;
  &lt;li&gt;Adding a &lt;a href=&quot;https://nodejs.org&quot;&gt;nodejs&lt;/a&gt; server which:
    &lt;ul&gt;
      &lt;li&gt;Listens for OSC notifications from &lt;code class=&quot;highlighter-rouge&quot;&gt;playSound.ck&lt;/code&gt;, converting the file name into three parts:
        &lt;ol&gt;
          &lt;li&gt;Sound contributor&lt;/li&gt;
          &lt;li&gt;Description of sound&lt;/li&gt;
          &lt;li&gt;Soundcloud track ID (if available)&lt;/li&gt;
        &lt;/ol&gt;
      &lt;/li&gt;
      &lt;li&gt;Broadcasts the data to connected browsers via websockets (or other appropriate technology via &lt;a href=&quot;https://github.com/sockjs&quot;&gt;sock.js&lt;/a&gt;)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Added &lt;a href=&quot;https://www.nginx.com&quot;&gt;nginx&lt;/a&gt; to proxy both the node server and the mp3 stream to downstream consumers&lt;/li&gt;
  &lt;li&gt;Adding javascript (humble &lt;a href=&quot;https://jquery.com/&quot;&gt;jQuery&lt;/a&gt;) to the homepage which updates the text under the player when a new track is played.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So far the Pi hasn’t taken on any extra load from these services (the bulk of the CPU usage lies - understandably - with chuck and darkice). Admittedly the Pi’s not serving many simultaneous connections. Still, what an awesome little machine, eh?&lt;/p&gt;

&lt;p&gt;There’s more work that could be done: as the metadata is currently bundled into the filename it’s tempting to set up a database to keep track of the data at the node end, and simplify the file names to simple ids. The db would be built in sqlite or maybe one of those fancy nosql dbs I’ve hearing about. So many possibilities…&lt;/p&gt;
</description>
        <pubDate>Sun, 30 Apr 2017 00:00:00 +1200</pubDate>
      </item>
    
      <item>
        <title>New sounds by Adrien Capozzi</title>
        <link>https://concrete-mixer.github.io/2017/04/new-sounds-adrien</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2017/04/new-sounds-adrien</guid>
        <description>&lt;p&gt;In my quest to get contributions to Concrete Mixer I’ve turned to muso friends with the view that, well, everyone who has dabbled in electronica has made field recordings, right? Well my LA-based chum &lt;a href=&quot;http://www.adrien75.com/adrien75.html&quot;&gt;Adrien Capozzi&lt;/a&gt; said he hadn’t, but that he’d make some, and a few days later emailed me two tracks. That’s exactly the sort of commitment to the cause we’re after!&lt;/p&gt;

&lt;h2 id=&quot;contributions&quot;&gt;Contributions&lt;/h2&gt;

&lt;h3 id=&quot;chimes-cambria&quot;&gt;Chimes Cambria&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/315506402&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Adrien didn’t provide any description of what either recording is about, so I don’t have much to go on except the titles. When I google ‘Chimes Cambria’ &lt;a href=&quot;http://www.lampsplus.com/products/cambria-chimes-antique-walnut-12-inch-wide-bulova-mantel-clock__v1929.html&quot;&gt;this&lt;/a&gt; is the result I get, but that doesn’t seem quite right. The chiming and occasional gonging sound great though, and the mystery endures…&lt;/p&gt;

&lt;h3 id=&quot;underwood-family-farm&quot;&gt;Underwood Family Farm&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/315506397&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Again there’s no context to this recording other than the title. My knowledge of American farming being fairly limited, I’m tempted to imagine this is the soundtrack to a &lt;a href=&quot;https://en.wikipedia.org/wiki/Barn_raising&quot;&gt;barn raising&lt;/a&gt;, though again I guess this isn’t very likely. No matter what the occasion happened to be, it sounds pretty relaxed. I’d like to have been there.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Thanks Adrien for adding your ingredients to Concrete Mixer’s sonic gumbo!&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 01 Apr 2017 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>New sounds by Rob Szeliga added to Concrète Mixer radio</title>
        <link>https://concrete-mixer.github.io/2017/03/new-sounds-rszeliga</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2017/03/new-sounds-rszeliga</guid>
        <description>&lt;p&gt;Our second sound donor (praise him with great praise!) is &lt;a href=&quot;http://www.rszoniq.com&quot;&gt;Rob Szeliga&lt;/a&gt;, a UK-based sound designer, and he’s sent through a nice range of recordings.&lt;/p&gt;

&lt;h2 id=&quot;contributions&quot;&gt;Contributions&lt;/h2&gt;

&lt;h3 id=&quot;prayers-at-osu-kannon-temple&quot;&gt;Prayers at Osu Kannon Temple&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/298454977&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This recording features a bit of tranquil bonging and chanting from a Buddhist temple in Japan. I’ve spent a bit of time in a few Japanese temples myself (a sign, I fear, of a misspent youth), so this recording brings back some memories of stone gardens, exquisite lawns, golden statues and, weirdly, eagles flying high over head.&lt;/p&gt;

&lt;p&gt;Incidentally, the base CM sound library includes a &lt;a href=&quot;https://soundcloud.com/concrete-mixer/enter-the-chamber-of-the-10000-buddhas&quot;&gt;recording I did at the Temple of Ten Thousand Buddhas in Sha Tin, Hong Kong&lt;/a&gt;. That lacks the tranquility of this recording, because it was Chinese New Year and it was crowded with people casting &lt;a href=&quot;https://en.wikipedia.org/wiki/Kau_cim&quot;&gt;fortune sticks&lt;/a&gt; to learn if they might get rich.&lt;/p&gt;

&lt;h3 id=&quot;wind-through-stone-wall&quot;&gt;Wind through stone wall&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/291877441&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This excellent recording really transports you to a rather windy day in the English countryside. Makes you want to put on another layer or two of clothing. And emigrate. Brr!&lt;/p&gt;

&lt;h3 id=&quot;the-horns-of-india&quot;&gt;The horns of India&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/289875405&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Firstly, the chaotic blarings of the bells are great - nice rich sound source, that - but Rob did a bit of granular synthesis to freeze the sounds in time and stretch them out into a sort of brief &lt;a href=&quot;https://en.wikipedia.org/wiki/Illbient&quot;&gt;illbient&lt;/a&gt; composition. I’ve excised the signal processing from the recording for CM in case anyone thinks it’s part of CM (if you think CM is capable of that kind of real-time DSP you’d be sadly mistaken).&lt;/p&gt;

&lt;p&gt;That said, it’s a nice piece of filtration and I feel a bit bad about the removal. Sorry Rob!&lt;/p&gt;

&lt;h3 id=&quot;midday-at-the-foundling-museum&quot;&gt;Midday at the Foundling Museum&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/311781201&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;It’s hard to imagine how midday could be signified with more gravitas than this clock manages.&lt;/p&gt;

&lt;h3 id=&quot;underground-screech&quot;&gt;Underground Screech&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/293762882&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;There have been times when I’ve been on the London Underground where I’ve been a little concerned I’d never made it back to the outside world. It’s certainly reassuring to hear a train in motion.&lt;/p&gt;

&lt;h3 id=&quot;traction-engines&quot;&gt;Traction Engines&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/282694272&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;TRACTION ENGINES!&lt;/p&gt;

&lt;h3 id=&quot;thanks-rob&quot;&gt;Thanks Rob!&lt;/h3&gt;
</description>
        <pubDate>Tue, 21 Mar 2017 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>New sounds by Sebastian Brock added to Concrète Mixer radio</title>
        <link>https://concrete-mixer.github.io/2017/03/new-sounds-bemtevi</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2017/03/new-sounds-bemtevi</guid>
        <description>&lt;p&gt;As mentioned last post I’m keen to add more sound recordings to &lt;a href=&quot;http://concrete-mixer.github.io/concrete-mixer.mp3&quot;&gt;Concrète Mixer Radio (CMR)&lt;/a&gt; and have &lt;a href=&quot;/concrète mixer radio/2017/02/12/call-for-field-recordings.html&quot;&gt;put out a call&lt;/a&gt; for contributions. I’ve also poked around on Soundcloud hitting up users asking for field recordings of theirs I like.&lt;/p&gt;

&lt;p&gt;Our first contributer is &lt;a href=&quot;http://bemtevi.de/&quot;&gt;Sebastian Brock&lt;/a&gt; (aka Bemtevi), who has &lt;a href=&quot;https://soundcloud.com/user-466564937&quot;&gt;many recordings on Soundcloud&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;contributions&quot;&gt;Contributions&lt;/h2&gt;

&lt;h3 id=&quot;hckerschwne-mute-swan-cygnus-olor&quot;&gt;Höckerschwäne (mute swan, &lt;em&gt;cygnus olor&lt;/em&gt;)&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/254959798&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This is a recording of some very unmute swan(s?) on Lake Werbeliner in northern Saxony (or so Wikipedia tells me). I love how the birds’ otherworldly calls are hypnotically locked in step. I also like how the sound’s pitch descends as the flying swans doppler their way into the distance.&lt;/p&gt;

&lt;p&gt;It sounds quite &lt;a href=&quot;https://en.wikipedia.org/wiki/Dub_music&quot;&gt;dubby&lt;/a&gt; to me. Would be good to drop a few seconds of swan over an &lt;a href=&quot;https://www.youtube.com/watch?v=ztq7-kkygZk&quot;&gt;Augustus Pablo track&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;wind-3---zaun-fence&quot;&gt;Wind 3 - Zaun (fence)&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/299761333&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This is quite an eerie recording and it will be interesting to see how it blends with the others in the sound pool. The fence seems to have been recorded using a contact microphone which means the sound has a smaller dynamic range (no high end, basically), which makes the recording sound like it’s been slowed down several octaves. Along with this discombobulation there’s a bleak science fictiony vibe to the recording. Kind of feels like the wind is groaning across an apocalyptic landscape…&lt;/p&gt;

&lt;h3 id=&quot;montpellier&quot;&gt;Montpellier&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/250477151&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;This recording catches several moods in the southern French town of Montpellier, from church bells to cafe conversation to what sounds like a very vigorous street parade. I cut this recording into several two minute sections which work in well with the other sounds in the mix.&lt;/p&gt;

&lt;h3 id=&quot;der-strand-von-nizza&quot;&gt;Der strand von Nizza&lt;/h3&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/273828849&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Oh this one’s excellent: the waves have a satisfying punch as they crash, and the sound of water rattling gravel as the waves ebb is tingly. Beautifully shaped white noise.&lt;/p&gt;

&lt;p&gt;Additionally, just above the the sound of the waves you can sometimes hear the voices of people on the beach. From my own recording experience I know it can be annoying to have extraneous noise when you want your aural subject to be isolated, but in this instance the human noise adds another dimension to the recording, grounding it in a real location. It really makes you feel like you’ve washed up on the French Riviera…&lt;/p&gt;

&lt;p&gt;Many thanks to Sebastian for letting me use his sounds!&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you want to hear more of Sebastian’s work you can check out &lt;a href=&quot;http://bemtevi.de/&quot;&gt;his website&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Mar 2017 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>Call for field recordings</title>
        <link>https://concrete-mixer.github.io/2017/02/call-for-field-recordings</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2017/02/call-for-field-recordings</guid>
        <description>&lt;p&gt;So as a side-project (or perhaps the main point?) of Concrète Mixer, I’ve set up an Icecast server running a live internet radio stream of the software’s output. Currently the supplied audio is recordings I’ve made, but I don’t get out so much these days so I’d like to open it up to recordings by other people.&lt;/p&gt;

&lt;p&gt;Some bullet points:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The ideal recording length seems to be about 90 to 150 seconds. Too short and the sound feels too abrupt; too long and the listener can lose interest.&lt;/li&gt;
  &lt;li&gt;I’m not after particularly high quality audio (some of my recordings were made on camcorders, dictaphones, mp3 players); that said, the recording has to be &lt;em&gt;fairly&lt;/em&gt; intelligible.&lt;/li&gt;
  &lt;li&gt;The recording has to have some sort innate interest, some element that engages a listener’s interest. I can’t really define that more than “I know it when I hear it”.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This probably isn’t an especially helpful guide. To provide something more concrete (haha!), here’s two SoundCloud playlists of the sounds I’m currently using, as a very loose guide.&lt;/p&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/playlists/283085828&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;iframe width=&quot;100%&quot; height=&quot;450&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/playlists/283082840&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&amp;amp;visual=true&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;&lt;br /&gt;
Sadly I’m not in a position to pay you for your contributions, but aside from the inherent glory you’ll gain in donating a recording to this project, I’ll do what I can to give you recognition.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;If you would like to submit a sound to be added to the Concrète Mixer live stream, please &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#099;&amp;#111;&amp;#110;&amp;#099;&amp;#114;&amp;#101;&amp;#116;&amp;#101;&amp;#109;&amp;#105;&amp;#120;&amp;#101;&amp;#114;&amp;#046;&amp;#097;&amp;#117;&amp;#100;&amp;#105;&amp;#111;&amp;#064;&amp;#103;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;email me&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
</description>
        <pubDate>Sun, 12 Feb 2017 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>What's new</title>
        <link>https://concrete-mixer.github.io/2017/02/whats-new</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2017/02/whats-new</guid>
        <description>&lt;p&gt;I last updated this blog in December 2015. In 2016 my time was rather swamped by work and fatherhood, but I tinkered away now and then and undertook some major work toward the end of last year. The result of this is Concrète Mixer 2.0, and this post outlines what’s changed.&lt;/p&gt;

&lt;h1 id=&quot;the-audio-is-much-the-same&quot;&gt;The audio is much the same&lt;/h1&gt;

&lt;p&gt;Firstly, the least impressive bit: the audio rendering is much the same as before. Some new processing has been added to playSound, and some tweaks to playFx have been made here and there, but there’s not too much different. I have other ideas but most of the effort has been aimed at refactoring the app to make it more stable and (frankly) sane.&lt;/p&gt;

&lt;h1 id=&quot;no-more-perl&quot;&gt;No more Perl&lt;/h1&gt;

&lt;p&gt;The biggest change to the codebase is that there’s no Perl wrapper for the app. Instead, the functionality formerly implemented in Perl has been rewritten in ChucK.&lt;/p&gt;

&lt;p&gt;This change was facilitated by my discovery that ChucK has FileIO and regular expression libraries which I can read and parse the config file. I’m a bit rueful I didn’t discover these libs earlier, although to be fair neither of them is documented on the ChucK website.&lt;/p&gt;

&lt;h1 id=&quot;hello-python---soundcloud-support&quot;&gt;Hello Python - Soundcloud support&lt;/h1&gt;

&lt;p&gt;Even as I dispensed with Perl, I had an idea to add SoundCloud support, and decided use the Python Soundcloud library.&lt;/p&gt;

&lt;p&gt;For a while I’d thought that Soundcloud support for users might be handy.&lt;/p&gt;

&lt;h2 id=&quot;how-it-works&quot;&gt;How it works&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Make a playlist in Soundcloud, making all the files downloadable&lt;/li&gt;
  &lt;li&gt;Put the playlist URL(s) into the concrete.conf file.&lt;/li&gt;
  &lt;li&gt;Concrete Mixer will progressively download the files from the playlist and play them when needed.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There’s support for most sound codecs via the lib-avconc library (aka ffmpeg). Soundcloud support makes evaluation of the app easier, and the default &lt;code class=&quot;highlighter-rouge&quot;&gt;concrete.conf.sample&lt;/code&gt; points to some demo playlists.&lt;/p&gt;

&lt;h1 id=&quot;concrte-mixer-in-docker&quot;&gt;Concrète Mixer in Docker&lt;/h1&gt;

&lt;p&gt;I’ve decided to remove the compiled binary and selected chugins from the CM distribution - it wasn’t really appropriate to sling binaries in a github repo, and it’s certainly easier to get users to compile ChucK themselves. However this means that a prospective user now needs to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;compile ChucK&lt;/li&gt;
  &lt;li&gt;compile chugins&lt;/li&gt;
  &lt;li&gt;install the supporting Python libs for Soundcloud support&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;…which is a bit messy. As a response to this, I’ve built a &lt;a href=&quot;https://github.com/concrete-mixer/cm-docker-rpi-dac&quot;&gt;Docker image&lt;/a&gt; which installs all these prerequisites and kicks off CM execution. This image is built with Raspbian to run on a Raspberry Pi.&lt;/p&gt;

&lt;h1 id=&quot;concrte-mixer-as-an-internet-radio-station&quot;&gt;Concrète Mixer as an internet radio station&lt;/h1&gt;

&lt;p&gt;Finally, I’ve made &lt;a href=&quot;https://github.com/concrete-mixer/cm-docker-rpi-internet&quot;&gt;another Docker image&lt;/a&gt; which augments Concrète Mixer with &lt;a href=&quot;http://www.darkice.org&quot;&gt;Darkice&lt;/a&gt; and &lt;a href=&quot;https://www.icecast.org&quot;&gt;Icecast&lt;/a&gt; to create a Concrète Mixer radio station. Despite the extra processing required, this setup runs pretty well on a Pi3. You can hear the result &lt;a href=&quot;http://concrete-mixer.venturus.io/concrete-mixer.mp3&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;things-to-come&quot;&gt;Things to come&lt;/h1&gt;

&lt;p&gt;The development of 2.0 has tidied up a lot of ugliness in the original build and suggest a way forward for the future.&lt;/p&gt;

&lt;h2 id=&quot;near-term---radio-concrte&quot;&gt;Near term - Radio Concrète&lt;/h2&gt;

&lt;p&gt;I’ve always had a question mark in my head over how punters would use Concrète Mixer, who they would be and why they would want to use it. As an occasional sound recordist who likes mashing up audio, the use case seems obvious to me, and I guess there are others who might be keen, but whether they’d want little boxes to do it or not is still unknown to me.&lt;/p&gt;

&lt;p&gt;Instead, Concrète Mixer as an internet radio station seems like a good focus to the project. The way forward seems to me to be to get more sounds, and refine the effects/playback system.&lt;/p&gt;

&lt;h2 id=&quot;longer-term&quot;&gt;Longer term&lt;/h2&gt;

&lt;p&gt;There’s still a lot that could be done on the audio front:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The effects chain is still mono (hidden with a bit of delay on a randomly selected channel&lt;/li&gt;
  &lt;li&gt;I have some more sound mashing ideas on playback that I haven’t explored yet. Some of these ideas (eg stereo reverb) will have to wait until more powerful Raspberry Pis are available.&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 07 Feb 2017 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>Randomness in sound</title>
        <link>https://concrete-mixer.github.io/2015/12/randomness</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2015/12/randomness</guid>
        <description>&lt;p&gt;A somewhat chin-strokey examination of how chance can be applied to open-ended electronic audio.&lt;/p&gt;

&lt;p&gt;When starting out writing audio processing scripts my plan was to devise a system that would generate sound sufficiently complex that by listening to it I wouldn’t be able to determine how it had been constructed.  I’m not sure quite why this idea interests me, but I guess I like suprises.&lt;/p&gt;

&lt;p&gt;The problem with this approach is that writing something that baffles you requires a lot of complexity and a lot of time - something at odds with the amount of time (generally, nocturnal dilettanting) that I can invest. Concrete Mixer ended up being a compromise. Take some real world sounds (ie don’t invest a lot of effort in complex signal generation) and devise a broad range of operations that could be applied to them, determined by chance.&lt;/p&gt;

&lt;h1 id=&quot;go-plenty-random&quot;&gt;Go plenty random&lt;/h1&gt;

&lt;p&gt;Concrete Mixer makes a lot of choices in determining the sound that is output:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The order in which sound files are played (and which consequently which files will be mixed with each other). Even with a few dozen files the number of possible combinations of sounds in a single render run is enormous.&lt;/li&gt;
  &lt;li&gt;The order in which effects are applied - there are 25 effects chains, which chosen randomly.&lt;/li&gt;
  &lt;li&gt;The amount of time an effect or sound playback manipulation is applied: each sound playback is divided into random stretches of time. For 7/8 of these segments, sample playback will proceed in a normal fashion; for the other 1/8 sound manipulation will be performed. Similarly, each effects chain is applied for a random period. Multiplying these factors, in any 20 second period some change in playback is being determined.&lt;/li&gt;
  &lt;li&gt;Further to this, each time some sound manipulation is performed, it may have many parameters that are determined randomly.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;What I really want to convey is that the parameter space for CM is huge and thus, however subtly it may seem, every time you listen to it it is playing in a way it has never played before, or will again.&lt;/p&gt;

&lt;p&gt;Additionally, part of the process of improving CM is providing even more choices and consequently more variety and uniqueness.&lt;/p&gt;

&lt;h1 id=&quot;but-never-go-full-random&quot;&gt;But never go full random&lt;/h1&gt;

&lt;p&gt;Randomness is good, but there’s a hefty constraint to be applied: whatever and however many decisions get made, the result has to sound good. There’s no point writing an app that regularly presents its sounds in a way that listeners don’t like.&lt;/p&gt;

&lt;p&gt;An early iteration of Concrete Mixer called Sound Forest frequently sounded poor, mostly because I had the parameter space for the effects chain so open that a often the choices made were nonsensical. Even so I remained undaunted: I even earnestly explained in the README file that although the app would often sound terrible, that this was in fact a virtue. Eventually it occurred to me that things had to be reined in a bit. I’ve always been sceptical about musicians who are enamoured with process over result, and going full random with awkward results is less ideal than providing a constrained but more rewarding set of possibilities.&lt;/p&gt;

&lt;p&gt;Even so, there’s no way that a computer arbitrarily making choices will always make the optimum choice for the sound files being played. Not without some fiendish piece of sound analysis. In this sense CM will never be the equal of a deliberate composition of Musique Concrete. Looking at it another way though, when an apt choice does get made, you can appreciate it more for being a product of chance rather than intent.&lt;/p&gt;
</description>
        <pubDate>Thu, 10 Dec 2015 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>About Concrète Mixer's effects chains</title>
        <link>https://concrete-mixer.github.io/2015/12/cm-fxchains</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2015/12/cm-fxchains</guid>
        <description>&lt;p&gt;This post discusses Concrete Mixer’s effects chains system, which is governed by the playFx entity within CM.&lt;/p&gt;

&lt;h1 id=&quot;why-effects&quot;&gt;Why effects?&lt;/h1&gt;

&lt;p&gt;Before we really get in to the discussion, it’s probably worth asking the fundamental question: why we need effects chains? For me there are two fundamental reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;to blend disparate sound sources&lt;/li&gt;
  &lt;li&gt;to dub it up a bit.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;blending-files&quot;&gt;Blending files&lt;/h2&gt;

&lt;p&gt;One or more raw recordings can be sound a bit sparse in the audio field, especially if they’re mono. An effects chain helps to add depth to the stereo field.&lt;/p&gt;

&lt;p&gt;In case you have recordings that are so bursting with incident they need no artificial enhancement, you can turn off the effects chain by specifying &lt;code class=&quot;highlighter-rouge&quot;&gt;fx_chain_enabled=0&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/concrete.conf&lt;/code&gt;).&lt;/p&gt;

&lt;h2 id=&quot;dubbing-it-up&quot;&gt;Dubbing it up&lt;/h2&gt;

&lt;p&gt;The main reason to alter a sound is to make it more interesting and/or appropriate for its intended use. My personal interest in this regard is similar to the approach taken in dub reggae, where vocal tracks are stripped back from the original multitrack and a variety of effects are applied to what’s left, in a manner convivial to herbal intoxication.&lt;/p&gt;

&lt;p&gt;There is of course an art to dub, and expecting a series of random effects choices to enhance a recording perfectly is to ask quite a bit. The secret is to have the effects change reasonably often (around a minute is good), so that if one combination comes up that ia suboptimal, there’s a good chance the next set will be more appropriate.&lt;/p&gt;

&lt;h1 id=&quot;how-the-effects-chains-work&quot;&gt;How the effects chains work&lt;/h1&gt;

&lt;p&gt;playFx defines 25 effects combinations. These chains are groupings of the effects libraries found in lib/Fx, like so:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-chuck&quot; data-lang=&quot;chuck&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;if ( choice == 1 ) {
    [
        new FxFilter,
        new FxDelay
    ] @=&amp;gt; fxChain;
}

if ( choice == 2 ) {
    [
        new FxDelayVariable,
        new FxDelay
    ] @=&amp;gt; fxChain;
}

if ( choice == 3 ) {
    [
        new FxDelay,
        new FxHarmonicDelay
    ] @=&amp;gt; fxChain;
}

// continued to choice 25&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;(In case you’re wondering, no, ChucK &lt;em&gt;doesn’t&lt;/em&gt; support &lt;code class=&quot;highlighter-rouge&quot;&gt;case&lt;/code&gt; statements.)&lt;/p&gt;

&lt;p&gt;The chains can be of arbitrary length, but the most you really want is four. This is partly because the cumulative result of too many effects is a mushy sound, but mostly because a Raspberry Pi has only limited CPU capacity and signal processing is expensive.&lt;/p&gt;

&lt;p&gt;You’ll note that each chain has a delay element. I think all the chains have some delay component, even if it’s reverb. It’s possible to have effects like flanging or frequency filters which track with the source sound in real time, but delay lines make the effects easier to discern, and also don’t muddy the sound of the original too much. If echoes killed your brother and you’d rather not hear them, you can always rewrite the chains by editing ‘lib/Modes/Concrete/playFxChain.ck`.&lt;/p&gt;

&lt;p&gt;Some Fx* classes (FxDelay and FxFilter being good examples) are wrappers for standard ChucK UGens. Others are custom (discussed below). ChucK users may be surprised that these effects have not been written as Chubgraphs (a convention for aggregating multiple Ugens together); this is for the simple reason that I hadn’t heard of them at the time I implemented Fx*. However, if I had my time over I definitely would, and it’s on the list for future refactoring.&lt;/p&gt;

&lt;h1 id=&quot;custom-fx-libs&quot;&gt;Custom Fx libs&lt;/h1&gt;

&lt;p&gt;The most interesting aspect of organising the effects chain for Concrete Mixer was to experiment with several ideas around Fx design. Most of these ideas have involved tinkering with existing ChucK UGens, but in mildly less conventional ways.&lt;/p&gt;

&lt;h2 id=&quot;fxdelayvariable&quot;&gt;FxDelayVariable&lt;/h2&gt;

&lt;p&gt;This effect randomly alters the delay amount, for the duration of the delay amount, meaning each echo is of different length to the last. This results in a skidding, skittering sound.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-chuck&quot; data-lang=&quot;chuck&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;fun void activity() {
    while ( active ) {
        // set duration for delay
        chooser.getDur( 0.05, 0.50 ) =&amp;gt; dur duration;

        duration =&amp;gt; delay.delay;
        duration - 400::samp =&amp;gt; dur mainDuration;

        // In the grand scheme of things we only need
        // duration =&amp;gt; now, but randomly changing delay
        // times means there are discontinuities in the signal.
        // To paper over these cracks (and pops) we fade the signal
        // around the discontinuities

        // fade in
        fader.fadeIn( 200::samp, 1.0, output );
        200::samp =&amp;gt; now;

        // work through mainDuration
        mainDuration =&amp;gt; now;

        // fade out
        fader.fadeOut( 200::samp, output );
        200::samp =&amp;gt; now;
    }
}&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;fxflanger&quot;&gt;FxFlanger&lt;/h2&gt;

&lt;p&gt;Flangers are a reasonably straightforward effect to produce. Flangers normally use a sine wave LFO to vary the delay value on the signal. With my implementation I’ve set an LFO on the feedback amount as well - I’m pretty sure I’ve never worked with a flanger that does this, though I guess it might be common. Certainly easy to do.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-chuck&quot; data-lang=&quot;chuck&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;fun void activity() {
    while ( active ) {
        lfo.osc( oscFreq, oscAmount, oscType ) =&amp;gt; float freqDelta;
        baseDelay::ms + freqDelta::ms =&amp;gt; flanger.delay;
        lfo.osc( volFreq, volAmount, volType ) =&amp;gt; feedback.gain;
        10::ms =&amp;gt; now;
    }
}&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Notes:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;flanger is a DelayA UGen.&lt;/li&gt;
  &lt;li&gt;This code is reasonably abstracted; the important part being the two lfo.osc lines. One oscillates the flanger object delay time, while the other oscillates the feedback.&lt;/li&gt;
  &lt;li&gt;The effect is recalculated every 10 milliseconds, which allows for LFO frequency resolution up to 50Hz.&lt;/li&gt;
  &lt;li&gt;When initialised, the randomised parameters for the flanger are calculated in two groups:
    &lt;ul&gt;
      &lt;li&gt;Slow mode - slow LFO frequency (less than 1Hz) and large feedback parameter&lt;/li&gt;
      &lt;li&gt;Fast mode - faster LFO frequency with a smaller feedback amount, producing more of a tremolo effect.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The result of all this is that by assigning different LFO rates to the flange delay time and to the flange feedback time, you end up with a more chaotic, varying sound.&lt;/p&gt;

&lt;h3 id=&quot;sample-hold-flanging&quot;&gt;Sample Hold Flanging&lt;/h3&gt;

&lt;p&gt;A further twist on the classic flanger is that every so often, rather than apply the flange effect with a sine wave LFO, the LFO type is set to sample hold. This gives us a flanger version of FxDelayVariable.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-chuck&quot; data-lang=&quot;chuck&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;fun string getOscType() {
    chooser.getInt( 1, 4 ) =&amp;gt; int choice;

    if ( choice == 1 ) {
        return &quot;sampleHold&quot;;
    }
    else {
        // we would go with sine 75% of the time
        return &quot;sine&quot;;
    }
}&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;fxharmonicdelay&quot;&gt;FxHarmonicDelay&lt;/h2&gt;

&lt;p&gt;This effect is halfway between a flanger and variable delay. Here the delay’s amount switches between notes in a harmonic series (the root notes being randomly assigned from a pool of midi frequencies). The harmonic pitches are defined from the delay amount, meaning that very short delay amounts must be used. To get the harmonic effect a large amount of feedback must be used, which can lead to a somewhat volatile result. Half the time an LFO is placed on the feedback amount, which makes the effect a bit more bearable.&lt;/p&gt;

&lt;p&gt;The harmonic ‘notes’ played are assigned randomly, so again the result is sample hold effect. Another interesting twist would be to assign a sequence of pitches that are continually repeated or gradually modulated.&lt;/p&gt;

&lt;h2 id=&quot;fxgate&quot;&gt;FxGate&lt;/h2&gt;

&lt;p&gt;Your father’s tremolo effect involves applying an LFO to a gain so that the volume of the signal rapidly drops out and returns. In Concrete Mixer this effect has been made a bit more interesting because the LFO frequency itself is modulated with an LFO. Similar to FxVariableDelay, this creates a bit of variable mayhem.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-chuck&quot; data-lang=&quot;chuck&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;    fun void activity() {
        while ( true ) {
            lfo.osc( lfoOscFreq, lfoOscAmount, &quot;sine&quot; ) =&amp;gt; float freqDelta;
            lfoBaseFreq + freqDelta =&amp;gt; float lfoFreqFinal;
            lfo.osc( lfoFreqFinal, amount, &quot;sine&quot; ) =&amp;gt; float gainDelta;
            0.5 + gainDelta =&amp;gt; g.gain;
            1::ms =&amp;gt; now;
        }
    }&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h2 id=&quot;fxreversedelay&quot;&gt;FxReverseDelay&lt;/h2&gt;

&lt;p&gt;This class relies on a custom Chugen called ReverseDelay. ReverseDelay is small enough to include here in full.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-chuck&quot; data-lang=&quot;chuck&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;public class ReverseDelay extends Chugen {
    float readArray[0];
    float writeArray[0];
    int readCount;
    int writeCount;
    float sample;

    fun void delay( int size ) {
        readArray.size( size );
        writeArray.size( size );
        size - 1 =&amp;gt; readCount;
    }

    fun float tick( float in ) {
        // if readArray.size(), delay() has not been called
        // do nothing
        if ( ! readArray.cap() ) {
            return in;
        }

        in =&amp;gt; writeArray[ writeCount ];
        readArray[ readCount ] =&amp;gt; sample;
        writeCount++;
        readCount--;

        if ( writeCount == writeArray.cap() ) {
            switchArrays();
        }

        return sample;
    }

    fun void switchArrays() {
        float tempArray[];

        // switch arrays
        readArray @=&amp;gt; tempArray;
        writeArray @=&amp;gt; readArray;
        tempArray @=&amp;gt; writeArray;

        // reset counts
        0 =&amp;gt; writeCount;
        readArray.cap() - 1 =&amp;gt; readCount;
    }
}&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The gist is that the current signal gets written to an array. Once the current array is full, it gets swapped with a second array. From then on values are read in reverse from the first array, providing the backwards delay signal, while current values get written to the second delay. This cycle repeats, and hey presto, reverse delay.&lt;/p&gt;

&lt;p&gt;The effect is very simple and it’s a surprise it (or perhaps a more acoustically sophisticated version) hasn’t been implemented natively in ChucK.&lt;/p&gt;

&lt;p&gt;Note: Chugens use a lot of system resources and this effect is not enabled by default for the Raspberry Pi.&lt;/p&gt;

&lt;h2 id=&quot;chugins&quot;&gt;Chugins&lt;/h2&gt;

&lt;p&gt;ChucK comes with a small number of effects components built in, but the language also supports Chugins, which are compiled signal processing modules which can be used like Ugens. Two are used in Concrete Mixer: Gverb and Bitcrusher. Gverb provides better quality reverb than ChucK’s native (and rather woeful) reverb Ugens. BitCrusher lowers bitrate and samplerate on a signal, turning it into metallic noise. These Chugins are incorporated into several CM effects chains.&lt;/p&gt;

&lt;h1 id=&quot;concludings&quot;&gt;Concludings&lt;/h1&gt;

&lt;p&gt;That’s an overview of Concrete Mixers effects system. There are other ideas I’d like to implement but at the moment there’s enough variety to be getting on with.&lt;/p&gt;
</description>
        <pubDate>Sun, 06 Dec 2015 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>How I got to using ChucK</title>
        <link>https://concrete-mixer.github.io/2015/12/chuck</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2015/12/chuck</guid>
        <description>&lt;p&gt;This is a brief outline of how I went from using ‘standard’ music making software and ended up coding in ChucK.&lt;/p&gt;

&lt;p&gt;When I started looking at doing audio software development I looked at several options. The way I write it sounds like I went about this task in a very precise way, but in reality I drifted in and out of things, with some dabbling occurring after I had already settled on ChucK.&lt;/p&gt;

&lt;p&gt;The intent of this post is to outline the “journey” I took in case it might be useful for others. The big caveat is that there’s nothing particularly definitive about the choices I’ve made or where I’ve ended up, so you’d be better in taking what’s written below as a starting point for your own evaluations rather than ignoring the options I passed on and going straight to ChucK.&lt;/p&gt;

&lt;h1 id=&quot;background&quot;&gt;Background&lt;/h1&gt;

&lt;p&gt;So until 2013 I’d spent the previous 11 years producing electronic music tracks of various kinds using &lt;a href=&quot;http://www.audiomulch.com&quot;&gt;AudioMulch&lt;/a&gt;, a nifty if decidedly lowkey (compared to Live/Reason/Logic/Yaddayadda) program for Windows and (eventually) Mac. While I enjoyed using Mulch, its development ground to a halt in the early part of this decade and the project is now moribund. (In my view, an open sourced Mulch would be a killer app for Linux audio, but I don’t think that will happen.)&lt;/p&gt;

&lt;p&gt;After a decade of Mulching I was keen to try something different. I dined with the devil and tried &lt;a href=&quot;https://www.ableton.com/en/live/&quot;&gt;Ableton Live&lt;/a&gt;, but I’ve never been keen on following the herd (however excellent their choice might be). I decided that if I was to make a change it should be radical, and I should try to make my own sound from as low a level as possible.&lt;/p&gt;

&lt;h1 id=&quot;priorities&quot;&gt;Priorities&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Being increasingly time poor, I didn’t want to have to an entire sound app myself (except, briefly, when I had a dabble).&lt;/li&gt;
  &lt;li&gt;It had to be Linuxy, preferably free/open source&lt;/li&gt;
  &lt;li&gt;It had to be able to run on a Raspberry Pi, because I wanted to make a sound generating box.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;the-evaluation&quot;&gt;The Evaluation&lt;/h1&gt;

&lt;h2 id=&quot;pure-data&quot;&gt;Pure Data&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://puredata.info/&quot;&gt;Pure Data&lt;/a&gt; is the open source implementation of &lt;a href=&quot;https://en.wikipedia.org/wiki/Max_%28software%29&quot;&gt;Max/MSP&lt;/a&gt; (Max on a Mac seems to be the defacto standard for the academic end of audio programming). I didn’t really do much pd coding, but I did watch the bulk of the videos of one of &lt;a href=&quot;https://en.wikipedia.org/wiki/Miller_Puckette&quot;&gt;Miller “MSP” Puckette&lt;/a&gt;’s &lt;a href=&quot;http://pd-la.info/pd-media/miller-puckette-mus171-videos/&quot;&gt;introductory courses on pd&lt;/a&gt;, which I greatly enjoyed and highly recommend.&lt;/p&gt;

&lt;p&gt;In the end I decided pd wasn’t for me. I was a bit reluctant about this, as pd is pretty cool, but coming from a web programming background I find pd’s visual programming paradigm a bit unintuitive, or at least more time-consuming to fathom. Also I’d become increasingly annoyed mousing about to make music.&lt;/p&gt;

&lt;h2 id=&quot;supercollider&quot;&gt;Supercollider&lt;/h2&gt;

&lt;p&gt;I had a brief look at &lt;a href=&quot;http://supercollider.github.io/&quot;&gt;SuperCollider&lt;/a&gt; but found the code layout (everything is wrapped up in braces) a bit frustrating. Again, it’s something I could come back to if I had sufficient motivation. Also, cool name…&lt;/p&gt;

&lt;h2 id=&quot;web-audio-api&quot;&gt;Web Audio API&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&quot;https://en.wikipedia.org/wiki/HTML5_Audio#Web_Audio_API_and_MediaStream_Processing_API&quot;&gt;web audio API&lt;/a&gt; is a standard for rendering audio in web browsers. When I looked at it in 2013 it was reasonably raw and only properly supported by Chrome. The API is interfaced with javascript, and as someone who has worked in JS for some time that did appeal.&lt;/p&gt;

&lt;h3 id=&quot;a-digression-about-mobile-apps-and-sound-art&quot;&gt;A digression about mobile apps and sound art&lt;/h3&gt;
&lt;p&gt;Several demo apps written using the API are available online, and they are impressive. If Android’s browser container supported it, there’s a good chance I might have written Concrete Mixer as a phone app.&lt;/p&gt;

&lt;p&gt;Two years on, however, I’m now of the view that building CM as a mobile app would have been a mistake. I don’t like the idea of a sound producing app being one a hundred apps on a user’s phone competing for their attention. 
To my mind the task of rendering sound worlds is a serious business, and Raspberry Pis, even though they are inexpensive and to some extent disposable, still feel more appropriate for this endeavour. More &lt;em&gt;honest&lt;/em&gt;, somehow.&lt;/p&gt;

&lt;h2 id=&quot;back-to-the-web-audio-api&quot;&gt;Back to the Web Audio API&lt;/h2&gt;

&lt;p&gt;So yes, back on topic, my main feeling is that the web audio API is best used as intended for interactive multimedia, rather than an audio-only application. I also find the API itself a bit cumbersome (compared to ChucK, see below). I would pay more attention if there was an implementation of it in nodejs but as far as I’m aware there’s nothing available &lt;a href=&quot;https://github.com/sebpiq/node-web-audio-api&quot;&gt;that isn’t alpha&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Again, there may be reasons in the future to use it, but not right now.&lt;/p&gt;

&lt;h2 id=&quot;perl&quot;&gt;Perl&lt;/h2&gt;

&lt;p&gt;Mid last year after I went on a tangent learning some audio processing techniques without ChucK doing the heavy lifting. I did this in Perl because it’s what I use in my day job and I wanted to save time. I ended up having a good fiddle and may write up a report on my experiments later. However I soon concluded that Perl isn’t the best platform for doing this long term.&lt;/p&gt;

&lt;h2 id=&quot;chuck&quot;&gt;ChucK&lt;/h2&gt;

&lt;p&gt;In the end I went with ChucK because it’s the simplest, most intuitive (for me anyway) language I came across. (This doesn’t mean it’s the best.)&lt;/p&gt;

&lt;p&gt;So &lt;a href=&quot;http://chuck.cs.princeton.edu/&quot;&gt;ChucK&lt;/a&gt; is a C++ish OO scripting language which describes itself as “strongly typed and strongly timed”. Time is tamed with the use of the &lt;code class=&quot;highlighter-rouge&quot;&gt;dur&lt;/code&gt; (duration) type as well as being able to delay execution in a very ‘timely’ (teehee!) context:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-chuck&quot; data-lang=&quot;chuck&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;441::samp =&amp;gt; dur interval; // 441 samples or 1/100 of a second

while ( 1 ) { // ie do this continually
    interval =&amp;gt; now; // wait for this duration to pass
    &amp;lt;&amp;lt;&amp;lt; &quot;I waited&quot;, interval, &quot;samples and then I did something&quot; &amp;gt;&amp;gt;&amp;gt;; // log to stdout

    // will print the above message 100 times a second
    // you would never want to do this
}&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;It should be reasonably clear that this is perfect for scheduling and sequencing changes in signal - be it pitch, timbre, silence, etc.&lt;/p&gt;

&lt;p&gt;ChucK’s other eccentricity is the &lt;code class=&quot;highlighter-rouge&quot;&gt;=&amp;gt;&lt;/code&gt; ‘ChucK’ assignment operator, which both assigns variables (back to front) as well as links audio components in the same way you might plug a guitar into an amp and from an amp into a mixer:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-chuck&quot; data-lang=&quot;chuck&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;// this listing demonstrates various uses of the =&amp;gt; operator

// declare signal generating/filtering elements
// in ChucK parlance these are generically called Ugens.
// instantiate a sawtooth oscillator called saw
// and a low pass filter called low pass
SawOsc saw, LPF lowpass;

// set the gain of the sawtooth osc to a quarter of maximum
// it is strongly advisable to do this
// note scale is logarithmic so this is actually -12ish decibels
0.25 =&amp;gt; saw.gain;

440 =&amp;gt; saw.freq; // initialise the oscillator frequency to A4
// note saw.freq(440) does the same thing
4000 =&amp;gt; int inty; // variable assignment

// set the lowpass filter to 4Khz (frequency response will roll
// off above this value with a steepness according to the filter
// type
inty =&amp;gt; saw.freq;

// route saw oscillator to lowpass and then on to the soundcard output
// and route that to the sound card (dac)
saw =&amp;gt; lowpass =&amp;gt; dac;

// note you can declare and chuck at the same time, so we could have gone:
// SawOsc saw =&amp;gt; LPF lowpass =&amp;gt; dac;

while ( 1 ) { // loop forever
    // Get some sample hold going

    // randomly assign the oscillator frequency
    Std.rand2f( 20, 4000 ) =&amp;gt; saw.freq;

    // randomly assign the filter frequency
    Std.rand2f( 20, 4000 ) =&amp;gt; lowpass.freq;

    // finally, move time on
    // you can define duration in both increments of time and samples
    0.5::second =&amp;gt; now; 
    
}&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;ChucKing durations to &lt;code class=&quot;highlighter-rouge&quot;&gt;now&lt;/code&gt; means advancing time. Once you have your components in place they will do their thing (ie oscillate or filter) without you having to worry about them doing it.&lt;/p&gt;

&lt;p&gt;When I studied ChucK all this made intuitive sense to me. Consequently I’ve ended up using ChucK for most of my recent tinkering.&lt;/p&gt;

&lt;h2 id=&quot;downsides&quot;&gt;Downsides&lt;/h2&gt;

&lt;p&gt;ChucK is 10 years old, and you’d expect a language of that age to be mature. However ChucK’s developer and userbase is small, and academic, and ChucK thus has few pressures on it. Development has focused on a narrow range of applications, notably “live programming”. I don’t dispute the suitability of this narrow focus, but it also means that ChucK often feels like a ‘toy language’, missing many features you’d expect. I guess I had better give examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Barebones syntax, eg no &lt;code class=&quot;highlighter-rouge&quot;&gt;case&lt;/code&gt; statements or much in the way of syntactic sugar.&lt;/li&gt;
  &lt;li&gt;No base library loading - you need to explicitly load every library file you want access to. You can’t just provide ChucK with a lib directory environment variable and have all libraries in that directory loaded automatically.&lt;/li&gt;
  &lt;li&gt;A lack of file system tools (for example, there is no way in ChucK to access the file system, other than to load ChucK files).&lt;/li&gt;
  &lt;li&gt;A lack of concern for memory leakage, or performance generally (a major problem for a sound system like Concrete Mixer which is intended to run indefinitely on a Raspberry Pi).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As mentioned before these drawbacks lead me to use a Perl wrapper to manage Concrete Mixer. This hasn’t been a massive inconvenience, but it would have been nice if Concrete Mixer could have been pure ChucK app.&lt;/p&gt;

&lt;h1 id=&quot;on-the-whole&quot;&gt;On the whole&lt;/h1&gt;

&lt;p&gt;My criticisms of ChucK are (in my view, obviously) reasonable, but I suspect if I had gone with any of the alternatives I could compile a list of different but equivalent drawbacks for them too, so singling out ChucK in this way is a little unfair. The fact is I’m still using ChucK and I’ve barely scratched the surface of its audio manipulation capabilities. I’m also unlikely to jump ship to another language any time soon. Although if you do know of something you think is better, let me know!&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Dec 2015 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>Perl sine wave demo</title>
        <link>https://concrete-mixer.github.io/2015/11/perl-sine-wave</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2015/11/perl-sine-wave</guid>
        <description>&lt;p&gt;There is no good reason to write audio code in Perl, but on the other hand, no reason not to, so here we go.&lt;/p&gt;

&lt;h1 id=&quot;piping-hot-sound&quot;&gt;Piping hot sound&lt;/h1&gt;

&lt;p&gt;Someone may have written an audio library for Perl which interfaces with Alsa in a ‘proper’ way, but there’s a grubbier and consequently more appropriate way of doing it: through the shell.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ perl script.pl | aplay -f cd&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This command pipes the output of a perl script to Alsa’s aplay utility, which can take a data stream as input. The &lt;code class=&quot;highlighter-rouge&quot;&gt;-f cd&lt;/code&gt; means fire the stream to the soundcard at a sample rate of 44Khz, which is the samplerate a CD uses.&lt;/p&gt;

&lt;p&gt;With this in play, you need to write a script that will generate an audio-appropriate stream of data. The simplest sound you can generate is white noise, because you just generate a set of random values within a 16 bit range of amplitudes. We’re a bit more sophisticated, than that, however, so we’re going to start by generating a sine wave:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-perl&quot; data-lang=&quot;perl&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;#!/usr/bin/perl&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;strict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;use&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;warnings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$PI&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;3.1415926&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Amplitude for signal, roughly 50% of max (32768) or -6db&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$amplitude&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16384&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;440&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Frequency in Hertz ('A4' note)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$sample_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;44100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# define time increment for calculating the wave&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$increment&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$sample_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# do this perpetually&lt;/span&gt;
    &lt;span class=&quot;nv&quot;&gt;$t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$increment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Time in seconds&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$amplitude&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;$freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$PI&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;pack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;v&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The guts of this script is &lt;code class=&quot;highlighter-rouge&quot;&gt;my $signal = $amplitude * sin($freq * 2 * $PI * $t);&lt;/code&gt;. This is high school maths/physics (I’m told, it’s all so long ago now I can’t actually remember :/). Essentially you generate a sine wave by rotating through a circle (2*pi radians) and plotting the sine of the angle of rotation (0 - 360, or phase) as an amplitude through time. (The preceding gibberish is my understanding, if you want a proper description please &lt;a href=&quot;https://en.wikipedia.org/wiki/Sine_wave&quot;&gt;consult wikipiedia&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Once you’ve got the $signal value you need to format it as a little-endian integeger:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;print pack(&quot;v&quot;, $signal);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;So you print to stdout and the shell does its piping and aplay does the rest.&lt;/p&gt;

&lt;h1 id=&quot;making-the-signal-more-interesting&quot;&gt;Making the signal more interesting&lt;/h1&gt;

&lt;p&gt;A sine wave is nice but you can do more interesting things than that. The first thing to do is modulate the pitch. The easiest way to do this is randomly module the pitch every so often:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-perl&quot; data-lang=&quot;perl&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$base_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1760&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;Hz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# maximum frequency&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22050&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# half a second @ 44100 samplerate&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;$t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$increment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Increment $t&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$amplitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;pack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;v&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;nv&quot;&gt;$n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;nv&quot;&gt;$freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$base_freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;We’ve added an additional while loop to iterate through a fixed number of samples before we randomly change the frequency. (&lt;code class=&quot;highlighter-rouge&quot;&gt;$freq = rand( 1 ) * $base_freq&lt;/code&gt; implies a range down to 0Hz, so be careful running this through speakers. &lt;a href=&quot;https://www.youtube.com/watch?v=gIzSZH6oqeM&quot;&gt;Watch your bass bins, I’m telling ya&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Incidentally, if you’re familiar with synthesizers, the above is equivalent to pitch-modulating sample hold.&lt;/p&gt;

&lt;h1 id=&quot;adding-echoes&quot;&gt;Adding echoes&lt;/h1&gt;

&lt;p&gt;For me the gold standard of any signal modulation is adding echoes. I grant you this will seem childish to proper DSP ninjas who like constructing fourth order &lt;a href=&quot;https://en.wikipedia.org/wiki/Chebyshev_filter&quot;&gt;Chebyshev filters&lt;/a&gt;, but for me the space that echoes provide really is the place.&lt;/p&gt;

&lt;p&gt;An echo means holding playing a signal for a period of time. Arrays are perfect for this: bung your stream’s sample in memory and retrieve them for playback later.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-perl&quot; data-lang=&quot;perl&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;c1&quot;&gt;# initialise array of zeroed integers for delay line&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;@delay&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22050&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# == half a second of signal delay&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;22050&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# half a second @ 44100 samplerate&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;$t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$increment&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;# Increment $t&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$t&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$amplitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;my&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal_delayed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;shift&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;@delay&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# make delayed_signal 6dB quieter than main signal&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;$signal_delayed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# mix the two signals together&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;$signal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal_delayed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;

        &lt;span class=&quot;c1&quot;&gt;# increment @delay with signal plus previously delayed signal&lt;/span&gt;
        &lt;span class=&quot;nb&quot;&gt;push&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;@delay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;pack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;v&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$signal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt;
        &lt;span class=&quot;nv&quot;&gt;$n&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;++&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

    &lt;span class=&quot;nv&quot;&gt;$freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;$base_freq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;So we’re sitll sample-holding the pitch of the sine wave as before, but we’re now setting and retrieving values from an array, and mixing it with at a quieter bolume (-6dB) with the current signal. It still seems miraculous to me that simple addition (at the per sample level) can impose a new sound on top of the old, but it does.&lt;/p&gt;

&lt;h1 id=&quot;where-does-this-take-us&quot;&gt;Where does this take us?&lt;/h1&gt;

&lt;p&gt;Mid last year I went some way towards building my own drum machine/note sequencer system in Perl, using MooseX. I had track sequences written in JSON structures, some effects like flanging, ring modulation, and even reverse echoes (hint: use two arrays, swap them as required, and read the one you’re not writing to backwards). So it was all going swimmingly until I checked the CPU usage on my laptop: 100% playing a mono drum machine sequence and monophonic note sequence. Such a simple rig in a commercial audio software package would be expected to use 1-2% CPU.&lt;/p&gt;

&lt;p&gt;I suspect the reason for this problem is that interpreted languages like Perl are just too inefficient to be calculating large numbers of samples in real time. I attempted to make things more efficient by batch rendering content rather than running through the entire stack to calculate each sample. This didn’t seem to make any improvement.&lt;/p&gt;

&lt;p&gt;What I took away is that compiled languages like C and C++ are more appropriate for this sort of application, and I promptly ceased my activities. Even so, if you have simple ideas you want to try out, and/or vast system resources, Perl can do it.&lt;/p&gt;
</description>
        <pubDate>Mon, 23 Nov 2015 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>Using dot to make charts</title>
        <link>https://concrete-mixer.github.io/2015/11/dot</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2015/11/dot</guid>
        <description>&lt;p&gt;As this is a software blog I may as well mention how I generated the charts in the last post. As background I’ve had experience in the past drawing flow charts in Visio and Fireworks (those were the days), and was looking for something similar. Being in Linux land I tried Inkscape and dia, but Inkscape was a bit bewildering and dia was a bit rubbish (sorry dia developers!). I knew vaguely of tools that could generate charts from text and tried flowchart.js, but found the whole business of rendering a chart by loading a web page a bit inelegant. In the end I found dot, part of the &lt;a href=&quot;http://graphviz.org/&quot;&gt;GraphViz package&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;the-output-flow-diagram&quot;&gt;The output flow diagram&lt;/h1&gt;

&lt;p&gt;To refresh your memory, here’s the output file:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cm-schematic-sensible.svg&quot; alt=&quot;Concrete Mixer flow diagram simplified&quot; /&gt;&lt;/p&gt;

&lt;h1 id=&quot;the-markup&quot;&gt;The markup&lt;/h1&gt;

&lt;p&gt;And here’s the underlying ‘dot’ code used to generate the file (sorry the syntax highlighting is a bit rubbish, but the &lt;a href=&quot;http://pygments.org/&quot;&gt;pygments&lt;/a&gt; lexer I found for this is a bit minimal):&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-dot&quot; data-lang=&quot;dot&quot;&gt;&lt;table style=&quot;border-spacing: 0&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter gl&quot; style=&quot;text-align: right&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;digraph  {
    /* declare chartwide settings */
    penwidth=2.0;
    labeljust=left;
    node [fontname=&quot;Helvetica&quot;,penwidth=&quot;2.0&quot;,fontcolor=white,style=filled];
    edge [penwidth=&quot;2.0&quot;];
    fontname=helvetica;
    fontsize=16;

    /* subgraphs allow you to group nodes */
    subgraph cluster_0 {
        node [fillcolor=chocolate,color=chocolate];
        graph [color=chocolate];
        label=&quot;Perl&quot;;
        fontcolor=chocolate;
        concretepm [label=&quot;Concrete.pm\nOSC server&quot;];
        node [fillcolor=brown,color=brown];
    }

    subgraph cluster_1 {
        node [fillcolor=darkorchid,color=darkorchid];
        graph [color=darkorchid];
        label=&quot;WAV files&quot;;
        fontcolor=darkorchid;
        main [label=&quot;Main&quot;];
        alt [label=&quot;Alt&quot;];
    }

    subgraph cluster_2 {
        graph [color=forestgreen];
        fontcolor=forestgreen;
        label=&quot;ChucK&quot;;
        node [fillcolor=forestgreen,color=forestgreen];
        playsound [label=&quot;playSound.ck&quot;];
        playfx [label=&quot;playFxChain.ck&quot;];
    }

    /* the rest of the chart markup defines edges between nodes plus non subgraph nodes */
    node [fillcolor=hotpink,color=hotpink];
    shell [label=&quot;Linux shell $&quot;,color=hotpink];
    edge [color=hotpink];
    shell -&amp;gt; concretepm;

    /* wav file flow */
    edge [color=darkorchid];
    main -&amp;gt; concretepm;
    alt -&amp;gt; concretepm;
    concretepm -&amp;gt; playsound;

    /* play*-OSC server interactions */
    edge [color=chocolate];
    concretepm -&amp;gt; playsound;
    concretepm -&amp;gt; playfx;
    playfx -&amp;gt; concretepm;
    playsound -&amp;gt; concretepm;

    /* audio connections through to the dac */
    node [fillcolor=steelblue,color=steelblue];
    edge [color=steelblue];
    playsound -&amp;gt; DAC;
    playsound -&amp;gt; playfx;
    playfx -&amp;gt; DAC;
}&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;The bulk of the markup is colour declarations and changes, so while this looks like a lot of work, the subgroup and and node interrelationships can be defined in about half the number of lines.&lt;/p&gt;

&lt;h1 id=&quot;installation-and-invocation&quot;&gt;Installation and invocation&lt;/h1&gt;

&lt;p&gt;Installing graphviz in debian/ubuntu land requires the following:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ sudo apt-get install graphviz&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;To generate an SVG all you have to run is:&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;$ dot -T svg -O cm-schematic-minimal.dot&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;…and an SVG file called cm-schematic-minimal.dot.svg is created.&lt;/p&gt;

&lt;h1 id=&quot;concludings&quot;&gt;Concludings&lt;/h1&gt;

&lt;p&gt;I’m not sure everyone will think writing 63 lines of code is better than spending 10 minutes with a graphical flowchart package to make the same chart. As a non-designer I likein the idea of marking up a text file and feeding it into a program so that it takes care of the layout, and it’s quite elegant (and portable) to have everything encapsulated in a single text file.&lt;/p&gt;

&lt;p&gt;If you want to learn more about dot &lt;a href=&quot;http://www.graphviz.org/pdf/dotguide.pdf&quot;&gt;this excellent guide&lt;/a&gt; will help you out.&lt;/p&gt;
</description>
        <pubDate>Fri, 20 Nov 2015 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>Gastroscopy of Concrète Mixer</title>
        <link>https://concrete-mixer.github.io/2015/11/internals</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2015/11/internals</guid>
        <description>&lt;p&gt;This post describes what Concrète Mixer is doing when it does its thing.&lt;/p&gt;

&lt;h1 id=&quot;complicated-diagram&quot;&gt;Complicated diagram&lt;/h1&gt;

&lt;p&gt;The following is a schematic I put together describing all the componentry in Concrete Mixer:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cm-schematic.svg&quot; alt=&quot;Concrete Mixer flow diagram&quot; /&gt;&lt;/p&gt;

&lt;p&gt;I started writing out what all this was doing and realised that in all honesty no one cares.&lt;/p&gt;

&lt;h1 id=&quot;simple-diagram&quot;&gt;Simple diagram&lt;/h1&gt;

&lt;p&gt;When you get down to it, what’s actually important is the pipeline for what the listener gets to hear. With this in mind, here’s a stripped down version of the diagram:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/img/cm-schematic-sensible.svg&quot; alt=&quot;Concrete Mixer flow diagram simplified&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Key:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The pink line denotes the app being initiated&lt;/li&gt;
  &lt;li&gt;Purples lines denote flow of file names&lt;/li&gt;
  &lt;li&gt;Brown lines: OSC messages and play* entity (re)invocation&lt;/li&gt;
  &lt;li&gt;Blue lines: flow of audio signal from the play* entities to the sound card,&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;whats-going-on---in-brief&quot;&gt;What’s going on - in brief&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;The audio processing is written in &lt;a href=&quot;http://chuck.cs.princeton.edu/&quot;&gt;ChucK&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The ChucK libraries are enveloped by a sticky layer of &lt;a href=&quot;https://www.perl.org&quot;&gt;Perl&lt;/a&gt; which is there to do the things ChucK can’t do.&lt;/li&gt;
  &lt;li&gt;The Perl layer identifies the audio files to play (from directories the user has specified in &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/concrete.conf&lt;/code&gt;)&lt;/li&gt;
  &lt;li&gt;There are two distinct sound entities in play:
    &lt;ul&gt;
      &lt;li&gt;playSound (of which there can be multiple concurrent instances)&lt;/li&gt;
      &lt;li&gt;playFxChain (of which there can be only one at a time)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;The app takes at least one but possibly two directories of WAV files as the sound source&lt;/li&gt;
  &lt;li&gt;The app will stop playback once it has run out of wave files to play, or, because ChucK leaks memory, when the app has used more than half the system RAM. Alternatively, if the user configures &lt;code class=&quot;highlighter-rouge&quot;&gt;endless_play=1&lt;/code&gt; in &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/concrete.conf&lt;/code&gt;, the app will restart rather than end, and will thus play perpetually.&lt;/li&gt;
  &lt;li&gt;The app operates an OSC server in Perl space which receives signals from playSound and playFxChain that they have completed their tasks, and will generate new instances of both, until there are no more files left to play.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;whats-going-on---less-briefly&quot;&gt;What’s going on - less briefly&lt;/h1&gt;

&lt;h2 id=&quot;playsound&quot;&gt;playSound&lt;/h2&gt;

&lt;p&gt;The playSound entity is there to play wave files. The entity gets passed a filename by the OSC server, and then loads the file for playback. The playback period is divided into random lengths of time (dertived from the &lt;code class=&quot;highlighter-rouge&quot;&gt;bpm&lt;/code&gt; value specified in &lt;code class=&quot;highlighter-rouge&quot;&gt;conf/global.conf&lt;/code&gt;) in which the sound can be altered in some way. For any given period, there is a 1/8 chance that playback will be altered. When the decision to alter playback is made, a further random choice is taken as to what should be done. Possibilities include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;reversing playback&lt;/li&gt;
  &lt;li&gt;changing the recording’s pan position (if the sound is mono)&lt;/li&gt;
  &lt;li&gt;adding an effect to the sound (eg echo, reverb)&lt;/li&gt;
  &lt;li&gt;chopping up the playback in weird ways.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In all there are 13 possible operations that can be performed. The 1/8 ratio of for doing something different is a value derived through experiment and in accordance with my taste. To my ears, it seems appropriate to keep the wave files performing normal playback most of the time, with occasional forays into non-standard transmission to make things interesting.&lt;/p&gt;

&lt;h2 id=&quot;playfxchain&quot;&gt;playFxChain&lt;/h2&gt;

&lt;p&gt;The playFxChain entity sets up an effects chain into which playSounds are fed. There are 25 different effects chains available. These chains contain different combinations of effects defined in lib/Fx, which has 14 different effects libraries available. Most of these effects are built in to ChucK but there are a few I’ve cobbled together. I might discuss these in a later post.&lt;/p&gt;

&lt;p&gt;playFxChains are instantiated for random periods of time, separate to playSounds. This means that a playFxChain instance may fade out during playback of one or more playSounds, only for a different chain to fade in moments later. The intended effect is an ever changing sound, with playSounds and playFxChains criss-crossing each other. Even when all sound happens to fade out at the same time, the result can still be interesting.&lt;/p&gt;

&lt;h2 id=&quot;the-osc-server&quot;&gt;The OSC server&lt;/h2&gt;

&lt;p&gt;In Perl space the app operates an OSC server. OSC stands for &lt;a href=&quot;https://en.wikipedia.org/wiki/Open_Sound_Control&quot;&gt;Open Sound Control&lt;/a&gt;, a simplish protocol that is intended to be a sort of &lt;a href=&quot;https://en.wikipedia.org/wiki/MIDI&quot;&gt;MIDI&lt;/a&gt; internet protocol. ChucK has OSC support, so it seemed the natural way for the ChucK to communicate with the Perl layer. So when each playSound and playFxChain instance have completed their task, they signal the OSC server, which will kick off another instance of the entity.&lt;/p&gt;

&lt;p&gt;So that, in a nutshell, is how Concrete Mixer works.&lt;/p&gt;
</description>
        <pubDate>Sun, 15 Nov 2015 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>About Concrète Mixer</title>
        <link>https://concrete-mixer.github.io/2015/11/concrete-mixer</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2015/11/concrete-mixer</guid>
        <description>&lt;p&gt;So this blog is mainly focused on Concrète Mixer, a sound app I’ve built to be run on a Raspberry Pi. In this post I brief description of the app as a starter. Later posts will get in to more detailed explorations.&lt;/p&gt;

&lt;h1 id=&quot;what-is&quot;&gt;What is?&lt;/h1&gt;

&lt;p&gt;Every time I think about what Concrète Mixer is, I come up with a new description. Today it’s: Concrète Mixer is an audio file mixing engine which generates “soundscapes” by applying random decisions about how the sounds should be arranged. You can supply any kind of sound file, but my ‘use case’ has been to mix field recordings I’ve made.&lt;/p&gt;

&lt;p&gt;You can learn how to install the app on the project’s &lt;a href=&quot;https://github.com/concrete-mixer/concrete-mixer/blob/master/README.md&quot;&gt;github page&lt;/a&gt;, bug for those who prefer a more audiovisual run through, I’ve made a youtube that attempts to explain what Concrète Mixer is and how to set it up:&lt;/p&gt;

&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/oGbAfF0j6Us&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;Being the first instructional video I’ve produced, it’s not exactly Scorsese (although it might be slightly Hitchcockian).&lt;/p&gt;

&lt;h1 id=&quot;audio-demos&quot;&gt;Audio demos&lt;/h1&gt;

&lt;p&gt;Finally, there are demo renditions of the application available:&lt;/p&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;166&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/225341813&amp;amp;color=ff5500&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&quot;&gt;&lt;/iframe&gt;

&lt;iframe width=&quot;100%&quot; height=&quot;166&quot; scrolling=&quot;no&quot; frameborder=&quot;no&quot; src=&quot;https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/225344033&amp;amp;color=ff5500&amp;amp;auto_play=false&amp;amp;hide_related=false&amp;amp;show_comments=true&amp;amp;show_user=true&amp;amp;show_reposts=false&quot;&gt;&lt;/iframe&gt;

&lt;p&gt;These recordings represent two separate run through of the app using the same set of field recordings. The audio is recorded as is with no post-processing or editing. Indeed I haven’t actually listened to them all the way through.&lt;/p&gt;

&lt;h1 id=&quot;whats-next&quot;&gt;What’s next?&lt;/h1&gt;

&lt;p&gt;The next post will be a deeper description of how the app works.&lt;/p&gt;
</description>
        <pubDate>Mon, 09 Nov 2015 00:00:00 +1300</pubDate>
      </item>
    
      <item>
        <title>What's going on here?</title>
        <link>https://concrete-mixer.github.io/2015/11/intro</link>
        <guid isPermaLink="true">https://concrete-mixer.github.io/2015/11/intro</guid>
        <description>&lt;p&gt;This is a blog about audio coding that rambles through the work I’ve done over the past couple of years. It will be mostly focused on the &lt;a href=&quot;https://github.com/concrete-mixer/concrete-mixer&quot;&gt;Concrète Mixer app&lt;/a&gt;, but will also cover a couple of side projects.&lt;/p&gt;
</description>
        <pubDate>Sat, 07 Nov 2015 00:00:00 +1300</pubDate>
      </item>
    
  </channel>
</rss>
